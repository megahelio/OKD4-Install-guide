
> [!tip] 
> T√≥matelo con calma esta es la parte que m√°s problemas suele causar.

Uso ``oc get clusteroperatos`` se puede abreviar ``oc get co`` para saber si la *console* web est√° operativa (y el resto del cluster). La salida se parece a esto:

```
[root@odk4-services ~]# oc get co
NAME                                       VERSION             AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
authentication                             4.18.0-okd-scos.9   False       True          True       12h     OAuthServerRouteEndpointAccessibleControllerAvailable: failed to retrieve route from cache: route.route.openshift.io "oauth-openshift" not found...
baremetal                                  4.18.0-okd-scos.9   True        False         False      12h
cloud-controller-manager                   4.18.0-okd-scos.9   True        False         False      12h
cloud-credential                           4.18.0-okd-scos.9   True        False         False      13h
cluster-autoscaler                         4.18.0-okd-scos.9   True        False         False      12h
config-operator                            4.18.0-okd-scos.9   True        False         False      12h
console                                    4.18.0-okd-scos.9   False       False         True       12h     RouteHealthAvailable: console route is not admitted
control-plane-machine-set                  4.18.0-okd-scos.9   True        False         False      12h
csi-snapshot-controller                    4.18.0-okd-scos.9   True        False         False      12h
dns                                        4.18.0-okd-scos.9   True        False         False      12h
etcd                                       4.18.0-okd-scos.9   True        False         False      12h
image-registry                             4.18.0-okd-scos.9   True        False         False      12h
ingress                                    4.18.0-okd-scos.9   True        True          True       12h     The "default" ingress controller reports Degraded=True: DegradedConditions: One or more other status conditions indicate a degraded state: DeploymentReplicasAllAvailable=False (DeploymentReplicasNotAvailable: 0/1 of replicas are available), CanaryChecksSucceeding=Unknown (CanaryRouteNotAdmitted: Canary route is not admitted by the default ingress controller)
insights                                   4.18.0-okd-scos.9   True        False         False      12h
kube-apiserver                             4.18.0-okd-scos.9   True        False         False      12h
kube-controller-manager                    4.18.0-okd-scos.9   True        False         True       12h     GarbageCollectorDegraded: error fetching rules: Get "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/rules": dial tcp 172.30.225.86:9091: connect: connection refused
kube-scheduler                             4.18.0-okd-scos.9   True        False         False      12h
kube-storage-version-migrator              4.18.0-okd-scos.9   True        False         False      12h
machine-api                                4.18.0-okd-scos.9   True        False         False      12h
machine-approver                           4.18.0-okd-scos.9   True        False         False      12h
machine-config                                                 True        True          True       12h     Unable to apply 4.18.0-okd-scos.9: error during waitForDaemonsetRollout: [context deadline exceeded, daemonset machine-config-daemon is not ready. status: (desired: 2, updated: 2, ready: 0, unavailable: 2)]
marketplace                                4.18.0-okd-scos.9   True        False         False      12h
monitoring                                                     False       True          True       12h     UpdatingPrometheusOperator: reconciling Prometheus Operator Admission Webhook Deployment failed: updating Deployment object failed: waiting for DeploymentRollout of openshift-monitoring/prometheus-operator-admission-webhook: context deadline exceeded: got 1 unavailable replicas
network                                    4.18.0-okd-scos.9   True        False         False      12h
node-tuning                                4.18.0-okd-scos.9   True        False         False      10m
olm                                        4.18.0-okd-scos.9   True        False         False      12h
openshift-apiserver                        4.18.0-okd-scos.9   True        False         False      12h
openshift-controller-manager               4.18.0-okd-scos.9   True        False         False      12h
openshift-samples                          4.18.0-okd-scos.9   True        False         False      12h
operator-lifecycle-manager                 4.18.0-okd-scos.9   True        False         False      12h
operator-lifecycle-manager-catalog         4.18.0-okd-scos.9   True        False         False      12h
operator-lifecycle-manager-packageserver   4.18.0-okd-scos.9   True        False         False      12h
service-ca                                 4.18.0-okd-scos.9   True        False         False      12h
storage                                    4.18.0-okd-scos.9   True        False         False      12h
```


> [!info] Regla de oro para entender lo que vamos a hacer
> - Los **namespaces** agrupan **pods**.
> - Los **pods** agrupan **contenedores**.
> 

La salida ideal ser√≠a todo el Available a True y el resto a false. Para explorar qu√© esta pasando en cada *namespace* podemos usar:

```
oc get pods -n <NAMESPACE>
```

> [!NOTE]
> -  El comando ``oc get namespaces`` devuelve una lista de todos los namespaces que se usan. 
> -  Si miramos la salida de ``oc get co`` el namespace del clusteroperator se suele corresponder con **openshift-{name del co}**.

En la salida de ``oc get pods -n openshift-kube-controller-manager`` vemos que hay un pod con errores.

```
NAME                                                         READY   STATUS      RESTARTS   AGE
installer-3-okd4-control-plane-1.lab.okd.local               0/1     Completed   0          13h
installer-4-okd4-control-plane-1.lab.okd.local               0/1     Completed   0          13h
installer-5-okd4-control-plane-1.lab.okd.local               0/1     Error       0          13h
installer-6-okd4-control-plane-1.lab.okd.local               0/1     Completed   0          12h
kube-controller-manager-okd4-control-plane-1.lab.okd.local   4/4     Running     0          12h
```

Para ver los logs del pod que falla: 

> [!NOTE] 
> - **NAMESPACE**: ``openshift-kube-controller-manager``
> - **POD**:  ``installer-5-okd4-control-plane-1.lab.okd.local``

```
oc logs -n openshift-kube-controller-manager installer-5-okd4-control-plane-1.lab.okd.local
```

Me result√≥ tambi√©n muy √∫til revisar la ultima secci√≥n de **EVENTS** de los comandos ``oc describe``:

Para 1 pod:
```
oc describe pod -n openshift-kube-controller-manager installer-5-okd4-control-plane-1.lab.okd.local
```
Para todos los pods del namespace:
```
oc describe pods -A -n openshift-kube-controller-manager
```

En mi proceso de instalaci√≥n me encontr√© con los siguientes errores:
[[Fix openshift-ingress router-default]]
[[Fix oauth-openshift  openshift-authentication]]

Ante imprevistos, la documentaci√≥n oficial, ChatGPT y paciencia.

> [!TODO] 
> Si me llega la paciencia igual me monto algo para explicar como van los ficheros de configuraci√≥n ``.yaml`` para que no sea todo tan abstracto pero primero tengo que entenderlo bien yo.

Tu objetivo es que el oc get co muestre todos los operadores disponibles. Cuando consigas esto deber√≠as poder acceder a ``https://console-openshift-console.apps.lab.okd.local/``  y logearte con kubeadmin y la contrase√±a que se gener√≥ durante la creaci√≥n de los .ign en la carpeta auth. 

Enhorabuena!!! ü•≥ü•≥üéâüéâ 
Ya formas parte del grupo selecto de personas que consiguieron desplegar OKD

![[login okd.png]]
> Esta imagen es de la 4.19 pero deber√≠as ver un panel de login similar (no s√© porque est√° en franc√©s) 

Los siguientes pasos antes de hacer uso de **OKD** es empezar con los **pv** y **pvc** para establecer un registro de im√°genes (lo que incluye el despliegue de un servidor **nfs** o un almacenamiento alternativo), se recomienda crear un usuario administrador distinto a **kubeadmin** sin problema y el despliegue de prueba de alg√∫n proyecto. Estos pasos los pude hacer sin problema siguiendo [la gu√≠a de Craig](https://itnext.io/guide-installing-an-okd-4-5-cluster-508a2631cbee   )

|             Previo              | Siguiente  |
| :-----------------------------: | :--------: |
| [[2. Lanzamiento de los nodos]] | [[4. Despliegue de persistencia]] |
