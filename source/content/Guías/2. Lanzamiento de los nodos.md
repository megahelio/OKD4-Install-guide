
> [!info] Algunos enlaces que me gustaría haber tenído cuando empecé.
> [Consola Redhad](https://console.redhat.com/iam/user-access/overview)
> 
> [Documentacion de redhat](https://docs.redhat.com/en/documentation/openshift_container_platform/4.18/html/postinstallation_configuration/configuring-multi-architecture-compute-machines-on-an-openshift-cluster#multi-architecture-verifying-cluster-compatibility_creating-multi-arch-compute-nodes-bare-metal)
> 
[Documentacion de OKD](https://docs.okd.io/4.18/installing/installing_bare_metal/upi/installing-bare-metal.html)
>
>[Aquí se descarga el pull secret](https://console.redhat.com/openshift/install/metal/multi)
>
>[Repositorio para descargar los binarios OKD](https://github.com/okd-project/okd/releases)
### Instalación de Binarios de OKD

Los binarios a instalar son ``kubectl`` ``oc`` que pertenecen a openshift-client-\[...\] y  ``openshift-install`` que pertenece a openshift-install-\[...\].

Aquí te descargas el client y el installer de la versión de okd y arquitectura que corresponda. En este caso usamos Alma Linux 9 => rhel9,  la versión que voy a intentar instalar es OKD4.18.

![[4.18.0-okd-scos.9.png]]
![[4.18.0-okd-scos.9 Assets list.png]]

Descomprimir

```
tar -zxvf openshift-client-linux-amd64-rhel9.tar.gz
tar -zxvf openshift-install-linux.tar.gz
```

Mover al PATH

```
sudo mv kubectl oc openshift-install /usr/local/bin/
```

Chequear con 

```
oc version 
openshift-install version
kubectl version --short --client
```

## Compilación ignition-configs

Personaliza [install-config.yaml.bak](install-config.yaml.bak.md) con tu propio sshkey y pullsecret. 

> [!hint] 
> - Usar ``ssh-keygen`` y copia el ``id_rsa.pub`` que genera en el ``sshkey`` del ``yaml``.
> - Descarga o copia el ``pullsecret`` de console de redhat (Enlace arriba de todo del documento) y pégalo en el ``yaml``.
> - Se pueden añadir más ``masters`` o ``workers`` modificando el número de ``replicas`` pero lo más rápido de desplegar es sin ``workers`` y se añaden una vez desplegado el ``master``. Si no se necesita alta disponibilidad llega con un ``master``.

Se puede usar [compile.sh](compile.sh.md) para generar los .ign hace lo siguiente:

- Borra y vuelve a crear install_dir
- Copia [install-config.yaml.bak](install-config.yaml.bak.md) y genera "manifests" 
- Deshabilita el uso de master como worker (sed)
- Crea los ignition-configs
- Actualiza los ficheros servidos por httpd
- Lanza wait-for bootstrap en modo debug

Una vez lanzado compile.sh empezaremos el despliegue de cada nodo (bootstrap y master) (los workers los lanzaremos al final, primero bootstrap y master, cuando tengamos master apagamos bootstrap y luego van los workers, tengo intención de explicarlo abajo). Se puede pulsar F2 durante el arranque de FCOS  para poder editar las siguientes variables.

```
coreos.inst.install_dev=<disco donde instalaremos ej /dev/sda>
coreos.inst.image_url=<ruta a fcos.raw.xz en services>
coreos.inst.ignition_url=<ruta a .ign en services>
```

> [!NOTE] Sobre el image_url
> Vinculado a la versión de los binarios hay una versión de Fedora CoreOS (FCOS) que se puede consultar con:[^1]
> 
> ```
>  openshift-install coreos print-stream-json | jq -r '.architectures.x86_64.artifacts.metal.formats["raw.xz"]'
> ```
> 
> Ejemplo:
> 
> ```
> https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/39.20231101.3.0/x86_64/fedora-coreos-39.20231101.3.0-live.x86_64.fcos.raw.xz
> 
> https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/39.20231101.3.0/x86_64/fedora-coreos-39.20231101.3.0-live.x86_64.fcos.raw.xz.sig
> ```

O lo que es equivalente y hemos preferido muchos, esperar a que arranque el FCOS y usar:

```
sudo coreos-installer install <disco donde instalaresmo> \
  --ignition-url=<ruta a .ign en services> \
  --image-url=<ruta a .fcos.raw.xz en services>
  --insecure-ignition
reboot
```

Como no se puede copiar y pegar en las máquinas de VMWare bootstrap, master y worker creamos los scripts [worker](worker.md) [master](master.md) [bootstrap](bootstrap.md) con la idea de que en cada nodo solo se ejectute (siendo 192.168.112.102:8080 el socket httpd de services):
#### Bootstrap

```
sudo loadkeys es
sudo curl -s 192.168.112.102:8080/b | sh
```
#### Master

```
sudo loadkeys es
sudo curl -s 192.168.112.102:8080/m | sh
```
#### Worker

```
sudo loadkeys es
sudo curl -s 192.168.112.102:8080/w | sh
```

[^1]: [[Instalación binario JQ]]

Los nodos se reiniciarán y tocará esperar. Para controlar el proceso ejecutamos:

```
openshift-install --dir=install_dir/ wait-for bootstrap-complete --log-level=debug
```

Esperar a ``INFO It is now safe to remove the bootstrap resources``
Apagar el nodo bootstrap. Sacarlo de la conf del haproxy. Reiniciar el servicio.

```
sudo sed '/ okd4-bootstrap /s/^/#/' /etc/haproxy/haproxy.cfg sudo systemctl reload haproxy
```

> [!tip] 
> En caso de fallos hay logs conectandote por ssh a bootstrap con ``ssh core@\<ip de bootstrap\>``  y ejecutando ``journalctl`` como indica al inidica al establecer conexión.

|                 Previo                 |               Siguiente                |
| :------------------------------------: | :------------------------------------: |
| [[1. Setup]] | [[3. La dichosa console]] |
